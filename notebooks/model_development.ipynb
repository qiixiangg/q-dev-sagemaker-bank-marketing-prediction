{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing Campaign Success Prediction - Model Development\n",
    "\n",
    "This notebook demonstrates a comprehensive Data Science Life Cycle (DSLC) for predicting bank marketing campaign success. The goal is to predict whether a client will subscribe to a term deposit.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The data is related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to assess if the product (bank term deposit) would be subscribed ('yes') or not ('no').\n",
    "\n",
    "### Features\n",
    "\n",
    "#### Bank Client Data\n",
    "1. age: numeric\n",
    "2. job: type of job\n",
    "3. marital: marital status\n",
    "4. education: education level\n",
    "5. default: has credit in default?\n",
    "6. housing: has housing loan?\n",
    "7. loan: has personal loan?\n",
    "\n",
    "#### Campaign Data\n",
    "8. contact: contact communication type\n",
    "9. month: last contact month of year\n",
    "10. day_of_week: last contact day of the week\n",
    "11. campaign: number of contacts performed during this campaign\n",
    "12. pdays: number of days that passed by after the client was last contacted\n",
    "13. previous: number of contacts performed before this campaign\n",
    "14. poutcome: outcome of the previous marketing campaign\n",
    "\n",
    "#### Economic Context Data\n",
    "15. emp.var.rate: employment variation rate - quarterly indicator\n",
    "16. cons.price.idx: consumer price index - monthly indicator\n",
    "17. cons.conf.idx: consumer confidence index - monthly indicator\n",
    "18. euribor3m: euribor 3 month rate - daily indicator\n",
    "19. nr.employed: number of employees - quarterly indicator\n",
    "\n",
    "#### Target Variable\n",
    "- y: has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n",
    "## DSLC Steps\n",
    "\n",
    "1. Data Collection & Loading\n",
    "2. Data Exploration & Analysis\n",
    "3. Data Preprocessing\n",
    "4. Feature Engineering\n",
    "5. Model Development & Training\n",
    "6. Model Evaluation\n",
    "7. Model Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading\n",
    "\n",
    "First, let's set up MLflow and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('classic')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLflow tracking\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")\n",
    "mlflow.set_experiment(\"bank-marketing-prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data if it doesn't exist\n",
    "data_dir = '../data/raw'\n",
    "data_file = 'bank-additional-full.csv'\n",
    "data_path = os.path.join(data_dir, data_file)\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Downloading dataset...\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\"\n",
    "    r = requests.get(url)\n",
    "    with open(\"../data/raw/bank-additional.zip\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    \n",
    "    # Unzip the file\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(\"../data/raw/bank-additional.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"../data/raw\")\n",
    "    print(\"Dataset downloaded and extracted successfully!\")\n",
    "else:\n",
    "    print(\"Dataset already exists!\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(data_path, sep=';')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration & Analysis\n",
    "\n",
    "Let's explore our dataset to understand:\n",
    "- Data quality (missing values, duplicates)\n",
    "- Feature distributions\n",
    "- Target distribution\n",
    "- Feature relationships with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\")\n",
    "display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTarget Distribution:\")\n",
    "display(df['y'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='y')\n",
    "plt.title('Target Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numeric features\n",
    "numeric_features = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', \n",
    "                   'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(data=df, x='y', y=feature)\n",
    "    plt.title(f'{feature} by Target')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', \n",
    "                       'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df_pct = df.groupby(feature)['y'].value_counts(normalize=True).unstack()\n",
    "    df_pct['yes'].sort_values().plot(kind='bar')\n",
    "    plt.title(f'Success Rate by {feature}')\n",
    "    plt.ylabel('Success Rate')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Based on our analysis, let's preprocess the data:\n",
    "1. Convert target to numeric\n",
    "2. Encode categorical features\n",
    "3. Scale numeric features\n",
    "4. Split data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to numeric\n",
    "df['y'] = (df['y'] == 'yes').astype(int)\n",
    "\n",
    "# Initialize label encoders for categorical features\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    label_encoders[feature] = LabelEncoder()\n",
    "    df[feature] = label_encoders[feature].fit_transform(df[feature])\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "X_val[numeric_features] = scaler.transform(X_val[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Development & Training\n",
    "\n",
    "We'll use XGBoost for this binary classification task and perform:\n",
    "1. Cross-validation training\n",
    "2. Hyperparameter tuning\n",
    "3. Final model training\n",
    "\n",
    "We'll track all experiments using MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model parameters\n",
    "base_params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.5,\n",
    "    'alpha': 2.5,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_weight': 3,\n",
    "    'tree_method': 'auto'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation training\n",
    "with mlflow.start_run(run_name=\"cv-training\"):\n",
    "    mlflow.log_params(base_params)\n",
    "    \n",
    "    # Create XGBoost classifier\n",
    "    model_cv = xgb.XGBClassifier(**base_params)\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(model_cv, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    print(f\"CV Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mean_cv_score\", cv_scores.mean())\n",
    "    mlflow.log_metric(\"cv_score_std\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'eta': [0.1, 0.3, 0.5],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"hyperparameter-tuning\"):\n",
    "    # Create base model\n",
    "    model_tune = xgb.XGBClassifier(**base_params)\n",
    "    \n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_tune,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Log best parameters and score\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"best_cv_score\", grid_search.best_score_)\n",
    "    \n",
    "    # Update base_params with best parameters\n",
    "    base_params.update(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model training with best parameters\n",
    "with mlflow.start_run(run_name=\"final-training\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_params(base_params)\n",
    "    \n",
    "    # Convert data to DMatrix format\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # Train the model\n",
    "    model = xgb.train(\n",
    "        params=base_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=150,\n",
    "        evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=10\n",
    "    )\n",
    "    \n",
    "    # Create model signature and input example\n",
    "    input_example = X_train.iloc[0:1]\n",
    "    signature = mlflow.models.infer_signature(\n",
    "        model_input=X_train,\n",
    "        model_output=model.predict(xgb.DMatrix(X_train.iloc[0:1]))\n",
    "    )\n",
    "    \n",
    "    # Log the model with signature and input example\n",
    "    mlflow.xgboost.log_model(\n",
    "        model,\n",
    "        \"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Let's evaluate our model using:\n",
    "1. ROC-AUC score\n",
    "2. Confusion matrix\n",
    "3. Feature importance\n",
    "4. Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_proba = model.predict(dtest)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test AUC: {auc_score:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "importance_scores = model.get_score(importance_type='gain')\n",
    "importance_df = pd.DataFrame(\n",
    "    list(importance_scores.items()),\n",
    "    columns=['Feature', 'Importance']\n",
    ").sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df.head(10), x='Importance', y='Feature')\n",
    "plt.title('Top 10 Feature Importance (Gain)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Export\n",
    "\n",
    "Save the model and necessary artifacts for production deployment. These files will be used by the ML Engineering team for model serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_model('../models/xgboost_model.json')\n",
    "\n",
    "# Save feature names and other metadata\n",
    "model_metadata = {\n",
    "    'feature_names': X.columns.tolist(),\n",
    "    'numeric_features': numeric_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'model_params': base_params,\n",
    "    'prediction_threshold': 0.5,\n",
    "    'metrics': {\n",
    "        'auc_score': auc_score\n",
    "    },\n",
    "    'label_mapping': {\n",
    "        feature: dict(zip(encoder.classes_, range(len(encoder.classes_))))\n",
    "        for feature, encoder in label_encoders.items()\n",
    "    },\n",
    "    'scaler_params': {\n",
    "        'mean': scaler.mean_.tolist(),\n",
    "        'scale': scaler.scale_.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../models/model_metadata.json', 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
